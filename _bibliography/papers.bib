---
---

@string{aps = {American Physical Society,}}

@article{liu2025superpositionyieldsrobustneural,
      title={Superposition Yields Robust Neural Scaling}, 
      author={Yizhou Liu and Ziming Liu and Jeff Gore},
      year={2025},
      journal = {The Thirty-Ninth Annual Conference on Neural Information Processing Systems (Oral)},
      pdf = {https://arxiv.org/abs/2505.10465},
      html = {https://arxiv.org/html/2505.10465},
      url = {https://arxiv.org/abs/2505.10465},
      code = {https://github.com/liuyz0/SuperpositionScaling},
      preview = {superposition.png},
      additional_info={. Superposition means that models represent more features than dimensions they have, 
      which is true for LLMs since there are too many things to represent in language. 
      We find that superposition leads to a power-law loss with width, leading to the observed neural scaling law.},
      selected={true} 
}

@article{liu2025focus,
      title={FOCUS: First Order Concentrated Updating Scheme}, 
      author={Yizhou Liu and Ziming Liu and Jeff Gore},
      year={2025},
      month = jan,
      journal = {arXiv preprint arXiv:2501.12243},
      eprint={2501.12243},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url ={https://arxiv.org/abs/2501.12243}, 
      pdf = {https://arxiv.org/abs/2501.12243},
      html = {https://arxiv.org/html/2501.12243},
      preview={FOCUS.gif},
      additional_info={. Gas with attraction force can be easily squeezed into a small volume. We followed this idea to design a new optimizer for stochastic optimization,
      which outperforms AdamW and Signum when gradient noise is large and the loss landscape is sharp. Our new algorithm turns out to be more stable and faster than AdamW in training GPT-2 (small)},
      code = {https://github.com/liuyz0/FOCUS},
      selected={true}
}

@article{liu2024ecosystem,
author = {Yizhou Liu  and Jiliang Hu  and Jeff Gore },
title = {Ecosystem stability relies on diversity difference between trophic levels},
journal = {Proceedings of the National Academy of Sciences},
volume = {121},
number = {50},
pages = {e2416740121},
month = dec,
year = {2024},
doi = {10.1073/pnas.2416740121},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2416740121},
pdf = {https://www.pnas.org/doi/pdf/10.1073/pnas.2416740121},
additional_info={. Ecologists continue to debate how biodiversity influences ecosystem stability. 
We found that after considering the trophic level structure in species interactions, stability does not depend on the absolute diversity but on the diversity difference between trophic levels},
preview={liu2024ecosystem.png},
code = {https://github.com/liuyz0/Critical-match},
selected={true}
}

@article{Liu2023quantumspeedups,
  doi = {10.22331/q-2023-06-02-1030},
  url = {https://doi.org/10.22331/q-2023-06-02-1030},
  title = {On {Q}uantum {S}peedups for {N}onconvex {O}ptimization via {Q}uantum {T}unneling {W}alks},
  author = {Liu, Yizhou and Su, Weijie J. and Li, Tongyang},
  journal = {{Quantum}},
  issn = {2521-327X},
  publisher = {{Verein zur F{\"{o}}rderung des Open Access Publizierens in den Quantenwissenschaften}},
  volume = {7},
  pages = {1030},
  month = jun,
  pdf = {https://quantum-journal.org/papers/q-2023-06-02-1030/pdf/},
  year = {2023},
  preview={Liu2023quantum.png},
  additional_info={. We analyzed when and why quantum tunneling can provide algorithmic speedup for nonconvex optimization (quantum tunneling vs. thermal fluctuation)},
  code = {https://github.com/liuyz0/Quantum-tunneling},
  selected={true}
}

